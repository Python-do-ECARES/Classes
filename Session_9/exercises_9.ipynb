{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises For Session 9 (Numpy and Numba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: A primer on Numpy\n",
    "\n",
    "Solve the exercises below to become acquainted with numpy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1: Warm-up\n",
    "Create a new function, call it \"numpy_trial\". Inside the function, do the following:\n",
    "\n",
    "- Inizialize a random 4x4 matrix and fill it with random numbers with a loop. (Hint: consider using [numpy.zeros](https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros.html))\n",
    "\n",
    "- Draw a random array with the same number of dimensions as before, but without using any loop. (Hint: [numpy.random.rand](https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.random.rand.html))\n",
    "\n",
    "- Multiply the two matrices and compute the inverse of the result (if it exists).\n",
    "\n",
    "- Reshape the final matrix. (Hint: [numpy.reshape](https://docs.scipy.org/doc/numpy/reference/generated/numpy.reshape.html))\n",
    "\n",
    "- Run the function and display the final result. (Hint: use print())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.2: Numpy for econometrics\n",
    "The script below generates a random panel data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Setup\n",
    "np.random.seed(208)\n",
    "ID            = 20\n",
    "Periods       = 5\n",
    "beta          = np.array([1, 0.5, 1.4, 3, 0.2, 5]) # True values\n",
    "\n",
    "# Define function\n",
    "def create_data(ID, Periods, beta):\n",
    "    \n",
    "    data_mu       = np.array([1, 0.7, -0.25, 0.6, 0.4, -0.1])                                              \n",
    "    data_var      = [ [ 1.0000,  -0.2962,    0.3144,    0.5061,   -0.0014,   0.0077],\n",
    "                    [-0.2962,   1.0000,    0.3082,    0.0301,   -0.0101,   0.5034],\n",
    "                    [ 0.3144,   0.3082,    1.0000,    0.7012,    0.6674,   0.6345],\n",
    "                    [ 0.5061,   0.0301,    0.7012,    1.0000,    0.1950,   0.2173],\n",
    "                    [-0.0014,  -0.0101,    0.6674,    0.1950,    1.0000,   0.1860],\n",
    "                    [ 0.0077,   0.5034,    0.6345,    0.2173,    0.1860,   1.0000] ]                       \n",
    "    year          = np.sum(np.kron(np.linspace(1,Periods,Periods),np.identity(ID)),0)                      \n",
    "    idx           = np.sum(np.kron(np.identity(Periods),np.linspace(1,ID,ID)),0)                           \n",
    "    X             = np.exp(np.array(np.random.multivariate_normal(data_mu, data_var, ID*Periods)))         \n",
    "    y             = X @ beta + np.random.normal(0,1,ID*Periods)\n",
    "    data          = np.c_[year, idx, X, y]\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Call function\n",
    "data = create_data(ID, Periods, beta)\n",
    "#print(pd.DataFrame(data))                                                                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a few moments to undestrand how to simulate data. When creating \"year\" and \"idx\", I make use of the kroenecker product ([np.kron](https://docs.scipy.org/doc/numpy/reference/generated/numpy.kron.html)) to create a matrix with year and ID indices. Then, I sum over rows to obtain a column vector with the desired indices. \n",
    "\n",
    "Create a new function, call it \"Pooled_OLS\", that takes a (y,X) as inputs and returns the Pooled OLS estimator of $\\beta$ as output. Inside the function, do the following\n",
    "\n",
    "- Using matrix multiplication, create your own Pooled OLS estimator of the vector beta. (Hint: use [np.linalg.inv](https://docs.scipy.org/doc/numpy/reference/generated/numpy.linalg.inv.html))\n",
    "\n",
    "- Compute the Pooled OLS standard errors.\n",
    "\n",
    "Run it with and without the [@njit](https://numba.pydata.org/numba-doc/dev/user/performance-tips.html) decorator. Do you notice any difference? Free feel to experiment a bit.\n",
    "\n",
    "**Note**. If you correctly write the \"Pooled_OLS\" function, you should get exactly the same result as if you run Pooled OLS using the python package statsmodel. It is reassuring to see that the estimated values are very close to the true ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.999\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.999\n",
      "Method:                 Least Squares   F-statistic:                          1.755e+04\n",
      "Date:                Tue, 21 Jan 2020   Prob (F-statistic):                   5.45e-141\n",
      "Time:                        08:41:35   Log-Likelihood:                         -137.48\n",
      "No. Observations:                 100   AIC:                                      287.0\n",
      "Df Residuals:                      94   BIC:                                      302.6\n",
      "Df Model:                           6                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1             1.0126      0.023     44.748      0.000       0.968       1.058\n",
      "x2             0.5377      0.028     18.895      0.000       0.481       0.594\n",
      "x3             1.1745      0.109     10.820      0.000       0.959       1.390\n",
      "x4             3.0552      0.053     57.685      0.000       2.950       3.160\n",
      "x5             0.2179      0.048      4.541      0.000       0.123       0.313\n",
      "x6             5.0004      0.058     86.780      0.000       4.886       5.115\n",
      "==============================================================================\n",
      "Omnibus:                        0.782   Durbin-Watson:                   1.829\n",
      "Prob(Omnibus):                  0.676   Jarque-Bera (JB):                0.347\n",
      "Skew:                           0.058   Prob(JB):                        0.841\n",
      "Kurtosis:                       3.264   Cond. No.                         9.37\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "model = sm.OLS(data[:,8], data[:,2:8])\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Getting Serious\n",
    "Propose your own solutions for exercises 1 and 2 at [Quantecon](https://python.quantecon.org/numpy.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
