{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dowloading Trade Data with the Comtrade API\n",
    "\n",
    "Many institutions including the World Bank, the Fed, or the ECB now provide access to their data bases through APIs (Automated Programming Interfaces). In this exercise we will use the United Nations Comtrade API to download trade flows. \n",
    "\n",
    "The trade data accessible through the API can also be downloaded manually through drop-down menus on the [comtrade website](https://comtrade.un.org/data/). But if one is interested in making multiple downloads the API will come in pretty handy. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working directory\n",
    "First, let us set up the working directory since we will download files from the UN comtrade. If you are running this notebook from the session 5 folder of your fork, you should have it as current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/moritz/Documents/GitHub/Classes/Session_5\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# The os.getcwd() returns a string, you can assign it to a variable if you need using var = os.getcwd(). \n",
    "# Then, var will be assigned to that string.\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create a folder to store the data, call it `/Data` inside your working directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"Data\", exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Documentation\n",
    "\n",
    "Every API comes with a documentation. To understand how to use the Comtrade API you **need** to look at the [UN Comtrade documentation here](https://comtrade.un.org/data/doc/api/) to get an idea of the parameters required to make a request. \n",
    "\n",
    "Let's start with a simple request using the `requests` package, we want: \n",
    "- Commodities\n",
    "- Annual frequency\n",
    "- Year 2013\n",
    "- HS Sector Classification\n",
    "- UK to World\n",
    "- Imports and exports \n",
    "\n",
    "Check out the url including these parameters!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your request was successful\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://comtrade.un.org/api/get?max=100000&type=C&freq=A&px=HS&ps=2013&r=826&p=0&rg=all&cc=ALL&fmt=csv&head=M\"\n",
    "\n",
    "data_1 = requests.get(url)\n",
    "\n",
    "if data_1.status_code == 200:\n",
    "    print(\"Your request was successful\")\n",
    "else:\n",
    "    print(f\"Error {data_1.status_code} on your request \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some initial remarks: Above you might receive the \"ChunkedEncodingError\" which stops your code. If you receive this before the function \"bilateral_requests\" is defined, just run again the block of code returning the error. Instead, if you get it in the bilateral_requests call, or in the blocks of code after that, just ignore it and read the rest of the code without running it. We have not used exception handling to solve this problem on purpose, since we want to show some of the problems you might have using the UN Comtrade API. At the end of this notebook we mention this (and other problems) and possible ways to solve them, but we leave it is an exercise to include those solutions in your code.\n",
    "\n",
    "You don't need to always print the status code when you download data. The HTTP code 200 means that the request was succesful and the object required has been returned. You can learn more about HTTP codes [here](https://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html). The use of HTTP codes helps when you want to use exception handling to deal with possible problems in retrieving data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have obtained an object as result from your query (in this case the csv file), you might want to store the file somewhere. In this case, we will use the *Data* folder of the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing .csv file in /home/moritz/Documents/GitHub/Classes/Session_5/Data/\n",
      "File .csv saved in /home/moritz/Documents/GitHub/Classes/Session_5/Data/\n"
     ]
    }
   ],
   "source": [
    "# Use one of the variables below depending on your OS.\n",
    "\n",
    "# For Windows\n",
    "#data_path = os.getcwd() + \"\\\\Data\\\\UK_world\"\n",
    "\n",
    "# For MacOS or Linux\n",
    "data_path = os.getcwd() + \"/Data/\"\n",
    "\n",
    "# Function to write csv for reporter and partner data\n",
    "def write(req, path, reporter = \"\", partner = \"\"):\n",
    "    \n",
    "    print(f\"Writing .csv file in {path}\")\n",
    "\n",
    "    # The function open below just opens the file defined as path in write mode. \n",
    "    # Then, while this file is open, the following line will write the text content of the request \n",
    "    # to this file (after some manipulation using join and replace)\n",
    "    with open(path + reporter + \"_\" + partner + \".csv\", 'w', newline = \"\") as f:\n",
    "        # This will access the content of our request, and we already know that it is a csv file. \n",
    "        # It will write that file in the directory that we specify as path.\n",
    "        f.write(\"\".join(req.text.replace(\";\",\"\")))\n",
    "    print(f\"File .csv saved in {path}\")\n",
    "\n",
    "    \n",
    "# Execute the Function    \n",
    "write(data_1, data_path, \"UK\", \"World\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good job! Now you should have the csv file inside the data folder. To start all over again, let's remove it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(data_path + \"_.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country IDs\n",
    "\n",
    "The API uses numeric ISO codes for specific countries. In order to retrieve a list of country codes, the API allows the following call (see Documentation!): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "[{'id': '4', 'text': 'Afghanistan'}, {'id': '8', 'text': 'Albania'}, {'id': '12', 'text': 'Algeria'}, {'id': '20', 'text': 'Andorra'}, {'id': '24', 'text': 'Angola'}, {'id': '660', 'text': 'Anguilla'}, {'id': '28', 'text': 'Antigua and Barbuda'}, {'id': '32', 'text': 'Argentina'}, {'id': '51', 'text': 'Armenia'}]\n"
     ]
    }
   ],
   "source": [
    "# This is the url to the json file with the id-country pairs\n",
    "url_country_values= \"https://comtrade.un.org/Data/cache/reporterAreas.json\"\n",
    "\n",
    "country_values = requests.get(url_country_values).json()[\"results\"]\n",
    "\n",
    "# Let's print the first 10 codes\n",
    "print(country_values[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get the format into a more convienent shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "# Object is of type\n",
    "print(type(country_values))\n",
    "# First item inside object is of type\n",
    "print(type(country_values[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'tuple'>\n",
      "[('4', 'Afghanistan'), ('8', 'Albania'), ('12', 'Algeria'), ('20', 'Andorra'), ('24', 'Angola'), ('660', 'Anguilla'), ('28', 'Antigua and Barbuda'), ('32', 'Argentina'), ('51', 'Armenia'), ('533', 'Aruba'), ('36', 'Australia'), ('40', 'Austria'), ('31', 'Azerbaijan'), ('44', 'Bahamas'), ('48', 'Bahrain'), ('50', 'Bangladesh'), ('52', 'Barbados'), ('112', 'Belarus'), ('56', 'Belgium'), ('58', 'Belgium-Luxembourg'), ('84', 'Belize'), ('204', 'Benin'), ('60', 'Bermuda'), ('64', 'Bhutan')]\n"
     ]
    }
   ],
   "source": [
    "# Below you can find two different ways to achieve the same result\n",
    "\"\"\"\n",
    "unpacked_id = []\n",
    "unpacked_countries = []\n",
    "for x in range(len(country_values)):\n",
    "    unpacked_id.append(country_values[x][\"id\"])\n",
    "    unpacked_countries.append(country_values[x][\"text\"])\n",
    "    \n",
    "unpacked_values = list(zip(unpacked_id, unpacked_countries))\n",
    "print(unpacked_values)\n",
    "\"\"\"\n",
    "unpacked_values = [(x, y) for entry in range(len(country_values)) for x, y in [(country_values[entry].get(\"id\"), country_values[entry].get(\"text\"))]]\n",
    "\n",
    "print(type(unpacked_values))\n",
    "print(type(unpacked_values[1]))\n",
    "print(unpacked_values[1:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we know the name of a country but not the id, which is what we need for the API request, we can construct a function that takes the name of the country as argument and return the associated id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The country Belgium is in the list with id 56\n",
      "56\n"
     ]
    }
   ],
   "source": [
    "def obtain_id(country_name):\n",
    "    for x in range(len(unpacked_values)):\n",
    "        if country_name in unpacked_values[x]:\n",
    "            print(f\"The country {country_name} is in the list with id {unpacked_values[x][0]}\")\n",
    "            i = unpacked_values[x][0]\n",
    "            return i\n",
    "    else:\n",
    "        print(f\"The country {country_name} is not on the list, check the exact name used by the UN comtrade for that country\")\n",
    "        \n",
    "# Let's try it:\n",
    "print(obtain_id(\"Belgium\"))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API Call\n",
    "\n",
    "Let's build another helper function. It creates new folders to store our data with the arguments:\n",
    "- Frequency\n",
    "- Sector classificiation\n",
    "- Year\n",
    "- Reporter\n",
    "\n",
    "Since we work on different OS, we will also add an argument that takes the string \"Windows\" or \"MacOS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def folder(frequency, classification, year, reporter, OS, month = \"\"):\n",
    "    if OS == \"Windows\":\n",
    "        path = os.getcwd() + \"\\\\Data\\\\\" + frequency + \"\\\\\" + classification + \"\\\\\" + year + month + \"\\\\\" + reporter\n",
    "        os.makedirs(path, exist_ok = True)\n",
    "        print(f\"The folder at {path} has been created.\")\n",
    "        return path + \"\\\\\"\n",
    "    elif OS == \"MacOS\":\n",
    "        path = os.getcwd() + \"/Data/\" + frequency + \"/\" + classification + \"/\" + year + month + \"/\" + reporter + \"/\"\n",
    "        os.makedirs(path, exist_ok = True)\n",
    "        print(f\"The folder at {path} has been created.\")\n",
    "        return path\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's creates the function with the actual call to the API. It should take as arguments the parameters required by the API. Use the name of a country instead of the id, which we can recover from the previous function. As arguments use:\n",
    "\n",
    "* \"frequency\" to which we will assign the value \"A\" or \"M\" to get the data frequency\n",
    "* \"classification\" that takes the values \"HS\", \"H4\", etc. depending on the calssification that we want to use\n",
    "* \"year\" for the data reference year\n",
    "* \"reporter\" the reporter country, we will recover the id using the previous function\n",
    "* \"partner\" same as reporter but for the trading partner\n",
    "\n",
    "For the other parameters in the URL fix the following values:\n",
    "* Commodities (type=C)\n",
    "* Obtaind data on imports and exports (rg=1,2)\n",
    "* For all the classification codes within a classification (cc=all)\n",
    "* The format returned is a csv file (fmt=csv)\n",
    "\n",
    "This function should return the object of the query (like we did with \"data_1 = requests.get(url)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are including a frequency argument in the function but we will always use the annual frequency data for this exercise. If you want to get monthly data you should adjust the function in the following way:\n",
    "* If you did read the documentation of the API, you should have noticed that the format of the parameter at annual frequency is 2017, 2016, etc.\n",
    "* Instead, for the monthly frequency you have 201701, 201702, etc. the second part is the month\n",
    "* To obtain this parameter, you should add another argument (called \"month\") to the function. You will use the values 01, 02, 03, etc. for this parameter\n",
    "* In the url_year part you should concatenate the year and month arguments to get the required values, i.e. 201701.\n",
    "* The only classification available for the monthly data is \"HS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_constructor_C(frequency, classification, year, reporter, partner, month = \"\"):\n",
    "    url_frequency = \"&freq=\" + frequency\n",
    "    url_classification = \"&px=\" + classification\n",
    "    url_year = \"&ps=\" + year + month\n",
    "    url_reporter = \"&r=\" + obtain_id(reporter)\n",
    "    url_partner = \"&p=\" + obtain_id(partner)\n",
    "    url_final = \"&rg=1,2&cc=ALL&fmt=csv&head=M\"\n",
    "    url = \"http://comtrade.un.org/api/get?max=100000&type=C\" + url_frequency + url_classification + url_year + url_reporter + url_partner + url_final\n",
    "    print(f\"The url for {classification} and trade flows between {reporter} and {partner} in {year + month} has been created. Processing request...\")\n",
    "    req = requests.get(url) \n",
    "    print(f\"The request for {classification}, {reporter}, {partner}, {year + month} has been completed. The HTTP code is: {req.status_code}\")\n",
    "    print(url)\n",
    "    return req"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let us try if the function is working properly. For now we will include it in a temporary function together with the folder function just to store the file. Then, we will check how to improve things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilateral_requests(frequency, classification, year, reporter, partner, OS, month = \"\"):\n",
    "    path = folder(frequency, classification, year, reporter, OS, month = month)\n",
    "    print(path)\n",
    "    req = query_constructor_C(frequency, classification, year, reporter, partner, month = month)\n",
    "    write(req, path, reporter, partner)\n",
    "    return req"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder at /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2017/France/ has been created.\n",
      "/home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2017/France/\n",
      "The country France is in the list with id 251\n",
      "The country Germany is in the list with id 276\n",
      "The url for H4 and trade flows between France and Germany in 2017 has been created. Processing request...\n",
      "The request for H4, France, Germany, 2017 has been completed. The HTTP code is: 200\n",
      "http://comtrade.un.org/api/get?max=100000&type=C&freq=A&px=H4&ps=2017&r=251&p=276&rg=1,2&cc=ALL&fmt=csv&head=M\n",
      "Writing .csv file in /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2017/France/\n",
      "File .csv saved in /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2017/France/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check your folder now, this should have created the csv file\n",
    "bilateral_requests(\"A\", \"H4\", \"2017\", \"France\", \"Germany\", \"MacOS\")\n",
    "# Let us try with monthly data\n",
    "#bilateral_requests(\"M\", \"HS\", \"2017\", \"France\", \"Germany\", \"MacOs\", month = \"01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything should be fine for now. Instead of bilateral data, try to get trade values between France and all its trading partners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder at /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2017/France/ has been created.\n",
      "/home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2017/France/\n",
      "The country France is in the list with id 251\n",
      "The country All is in the list with id all\n",
      "The url for H4 and trade flows between France and All in 2017 has been created. Processing request...\n",
      "The request for H4, France, All, 2017 has been completed. The HTTP code is: 200\n",
      "http://comtrade.un.org/api/get?max=100000&type=C&freq=A&px=H4&ps=2017&r=251&p=all&rg=1,2&cc=ALL&fmt=csv&head=M\n",
      "Writing .csv file in /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2017/France/\n",
      "File .csv saved in /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2017/France/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bilateral_requests(\"A\", \"H4\", \"2017\", \"France\", \"All\", \"MacOS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you check the last file, you will notice that the request was successful but we did not get the data since the number of observations is above the limit. Usually, it is better to receive an error when you make the request that exceed the limit instead of a successful request code. However, this is how the UN Comtrade deisgned its API. Anyway, we can take a step back to avoid this problem. If you did check the API documentation, the UN Comtrade has a separate file to check the data availability (it returns a json with multiple informations). Let us define a couple of functions to use this data availability request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_availability_C(frequency, classification, year, reporter, partner = \"\", month = \"\"):\n",
    "    url_frequency = \"http://comtrade.un.org/api/refs/da/view?type=C&freq=\" + frequency\n",
    "    url_classification = \"&px=\" + classification\n",
    "    url_year = \"&ps=\" + year + month\n",
    "    url_reporter = \"&r=\" + obtain_id(reporter)\n",
    "    if partner == \"\":\n",
    "        url_partner = \"&p=\"\n",
    "    elif partner != \"\":\n",
    "        url_partner = \"&p=\" + obtain_id(partner)\n",
    "    url_final = \"&rg=1,2&cc=ALL\"\n",
    "    url = url_frequency + url_classification + url_year + url_reporter + url_partner + url_final\n",
    "    print(f\"The url for {classification} and trade flows between {reporter} and {partner} in {year + month} has been created. Processing data availability file...\")\n",
    "    req = requests.get(url).json()\n",
    "    print(f\"The json for {classification}, {reporter}, {partner}, {year + month} is now available. Now it is time to unpack it.\")\n",
    "    unpacked = [(x) for entry in range(len(req)) for x in req[entry].items()]\n",
    "    print(unpacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, start from our previous query on annual data between France and Germany."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The country France is in the list with id 251\n",
      "The country Germany is in the list with id 276\n",
      "The url for H4 and trade flows between France and Germany in 2017 has been created. Processing data availability file...\n",
      "The json for H4, France, Germany, 2017 is now available. Now it is time to unpack it.\n",
      "[('type', 'COMMODITIES'), ('freq', 'ANNUAL'), ('px', 'H4'), ('r', '251'), ('rDesc', 'France'), ('ps', '2017'), ('TotalRecords', 684593), ('isOriginal', 0), ('publicationDate', '2018-08-24T00:00:00'), ('isPartnerDetail', 1)]\n"
     ]
    }
   ],
   "source": [
    "query_availability_C(\"A\", \"H4\", \"2017\", \"France\", partner = \"Germany\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the data availabilty json is good if you have problems for observations between a reporter country and all its trade partners, while it is useless to solve the observation problem should it arise for bilateral flows (it should not since UN Comtrade increase the max size of the request). We did include a partner paramater but the request ignored it since it is not a paramenter of the data availability query. The request sent us the number of observations for all trade flows (including re-exports and re-imports) between the reporter country and all trade partners."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check the availability for the monthly data just for fun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The country France is in the list with id 251\n",
      "The country All is in the list with id all\n",
      "The url for HS and trade flows between France and All in 201701 has been created. Processing data availability file...\n",
      "The json for HS, France, All, 201701 is now available. Now it is time to unpack it.\n",
      "[('type', 'COMMODITIES'), ('freq', 'MONTHLY'), ('px', 'HS'), ('r', '251'), ('rDesc', 'France'), ('ps', '201701'), ('TotalRecords', 373901), ('isOriginal', 1), ('publicationDate', '2018-08-22T00:00:00'), ('isPartnerDetail', 1)]\n"
     ]
    }
   ],
   "source": [
    "query_availability_C(\"M\", \"HS\", \"2017\", \"France\", partner = \"All\", month = \"01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same problem as before, we only get aggregate observations for France."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean the Data folder by deleting the csv files. We could also write down a function to do that. You can do that as an exercise, you will need to look at some of the functions in the os library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Windows\n",
    "#os.remove(os.getcwd() + \"\\\\Data\\\\A\\\\H4\\\\2017\\\\France\\\\France_Germany.csv\")\n",
    "#os.remove(os.getcwd() + \"\\\\Data\\\\A\\\\H4\\\\2017\\\\France\\\\France_All.csv\")\n",
    "#os.remove(os.getcwd() + \"\\\\Data\\\\M\\\\HS\\\\201701\\\\France\\\\France_Germany.csv\")\n",
    "\n",
    "# For MacOS\n",
    "os.remove(os.getcwd() + \"/Data/A/H4/2017/France/France_Germany.csv\")\n",
    "os.remove(os.getcwd() + \"/Data/A/H4/2017/France/France_All.csv\")\n",
    "#os.remove(os.getcwd() + \"/Data/M/HS/201701/France/France_Germany.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look at some of the problems that you might have using the UN Comtrade API without a license below. First, we will create a for loop to make requests for bilateral data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We might include an elif to avoid the request for the \"All\" partner, but we do not know if, at least for some reporter country (maybe small countries) it works because there are less observations\n",
    "def reporter_requests(frequency, classification, year, reporter, OS, month = \"\"):\n",
    "    index = 0\n",
    "    for x in range(len(unpacked_values)):\n",
    "        if reporter == unpacked_values[x][1]:\n",
    "            continue\n",
    "        else:\n",
    "            req = bilateral_requests(frequency, classification, year, reporter, unpacked_values[x][1], OS, month = month)\n",
    "            index += 1\n",
    "            if req.status_code != 200:\n",
    "                print(f\"The request was not successful for {frequency}, {classification}, {year + month}, {reporter}, {unpacked_values[x][1]}\")\n",
    "                break\n",
    "            elif index == 4:\n",
    "                print(f\"Since this is only an example, we stop at the index {index} since you might not want to download all the bilateral data for {reporter} in {year + month}\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder at /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2017/France/ has been created.\n",
      "/home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2017/France/\n",
      "The country France is in the list with id 251\n",
      "The country All is in the list with id all\n",
      "The url for H4 and trade flows between France and All in 2017 has been created. Processing request...\n",
      "The request for H4, France, All, 2017 has been completed. The HTTP code is: 200\n",
      "http://comtrade.un.org/api/get?max=100000&type=C&freq=A&px=H4&ps=2017&r=251&p=all&rg=1,2&cc=ALL&fmt=csv&head=M\n",
      "Writing .csv file in /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2017/France/\n",
      "File .csv saved in /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2017/France/\n",
      "The folder at /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2017/France/ has been created.\n",
      "/home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2017/France/\n",
      "The country France is in the list with id 251\n",
      "The country Afghanistan is in the list with id 4\n",
      "The url for H4 and trade flows between France and Afghanistan in 2017 has been created. Processing request...\n",
      "The request for H4, France, Afghanistan, 2017 has been completed. The HTTP code is: 200\n",
      "http://comtrade.un.org/api/get?max=100000&type=C&freq=A&px=H4&ps=2017&r=251&p=4&rg=1,2&cc=ALL&fmt=csv&head=M\n",
      "Writing .csv file in /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2017/France/\n",
      "File .csv saved in /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2017/France/\n",
      "The folder at /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2017/France/ has been created.\n",
      "/home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2017/France/\n",
      "The country France is in the list with id 251\n",
      "The country Albania is in the list with id 8\n",
      "The url for H4 and trade flows between France and Albania in 2017 has been created. Processing request...\n",
      "The request for H4, France, Albania, 2017 has been completed. The HTTP code is: 200\n",
      "http://comtrade.un.org/api/get?max=100000&type=C&freq=A&px=H4&ps=2017&r=251&p=8&rg=1,2&cc=ALL&fmt=csv&head=M\n",
      "Writing .csv file in /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2017/France/\n",
      "File .csv saved in /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2017/France/\n",
      "The folder at /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2017/France/ has been created.\n",
      "/home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2017/France/\n",
      "The country France is in the list with id 251\n",
      "The country Algeria is in the list with id 12\n",
      "The url for H4 and trade flows between France and Algeria in 2017 has been created. Processing request...\n",
      "The request for H4, France, Algeria, 2017 has been completed. The HTTP code is: 200\n",
      "http://comtrade.un.org/api/get?max=100000&type=C&freq=A&px=H4&ps=2017&r=251&p=12&rg=1,2&cc=ALL&fmt=csv&head=M\n",
      "Writing .csv file in /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2017/France/\n",
      "File .csv saved in /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2017/France/\n",
      "Since this is only an example, we stop at the index 4 since you might not want to download all the bilateral data for France in 2017\n"
     ]
    }
   ],
   "source": [
    "reporter_requests(\"A\", \"H4\", \"2017\", \"France\", \"MacOS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us mention a couple of problems that you might find using the UN Comtrade API:\n",
    "1. If you got an error at some point the loop will break. There are a couple of possible explanation for this:\n",
    " * We know that the request for the parameters above is well defined (meaning that the data are available, believe me on this). However, as we have seen before, they might exceed the number of observations available to free users. We have seen that this still return an HTTP code equal to 200, so it does not break the loop (more on this below). More on how to deal with large number of observations below.\n",
    " * Most likely, the problem is that free users can send 1 request per second. Since the files for the bilateral data are quite small, the loop might cycle requests really fast. In that case, you should get an HTTP code different from 200, breaking the loop. To avoid this, we can just import the time library and include a time.sleep(1) inside the loop.\n",
    " * You exceed the number of requests (100) that free users can make to the API in a 60 minutes window. To keep track of this, we can add an index = 0 at the beginning of the function, and increase it by 1 with each iteration of the for loop. Then, just add an if statement that, when the index is close to 100, uses time.sleep() for a sufficient number of minutes to reset the counter. Inside the function, after the time.sleep(), you can reset the index and go back to the iterations of the loop. Otherwise, instead of the counter, you can use exception handling to tell the code to sleep once the API returns the error (using an HTTP code) associated to the user request limit. When you hit the limit you receive a 409 HTTP code, which would stop the code, and the first row of the last file donwloaded will tell you why you received the error and, if the error was cause by the requests limit per hour, the time in which you can get back to sending requests. You could import in Python the first row from that file to extract, using regular expressions, the time to resume the requests, and use it to restart the loop creating the requests. We will not provide the code to do that here since we already cover a lot of topics in this session.  \n",
    "2. The loop stops after you have already completed a certain amount of iterations. This might happen for multiple reasons such as a loss of internet connection which leads to an error when you try to make the request or you simply interrupt the code by hand to close the notebook. In that case, you do not want to download again files that you have already stored in your folder, since it will burn your number of available requests per hour. Below we address this problem using a function that tells you whether a file is already stored in your folder and, in that case, does not submit a request since you already have the file. Below we do not provide the code to deal handle the exception from the loss of internet connection during a request. Try to write it without our help!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below the function to check the existing files in your folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_existence(frequency, classification, year, reporter, partner, OS, month = \"\"):\n",
    "    if OS == \"Windows\":\n",
    "        try:\n",
    "            if reporter + \"_\" + partner + \".csv\" in os.listdir(os.getcwd() + \"\\\\Data\\\\\" + frequency + \"\\\\\" + classification + \"\\\\\" + year + month + \"\\\\\" + reporter):\n",
    "                print (f\"File {reporter}_{partner}.csv already exists, skip to next iteration.\")\n",
    "                return True\n",
    "        except FileNotFoundError:\n",
    "                print (f\"The folder does not exist, implying that the file {reporter}_{partner}.csv does not exist, continue with this iteration.\")\n",
    "    elif OS == \"MacOS\":\n",
    "        try:\n",
    "            if reporter + \"_\" + partner + \".csv\" in os.listdir(os.getcwd() + \"/Data/\" + frequency + \"/\" + classification + \"/\" + year + month + \"/\" + reporter):\n",
    "                print (f\"File {reporter}_{partner}.csv already exists, skip to next iteration.\")\n",
    "                return True\n",
    "        except FileNotFoundError:\n",
    "                print (f\"The folder does not exist, implying that the file {reporter}_{partner}.csv does not exist, continue with this iteration.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Slightly modify the reporter_requests function defined above to include this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reporter_requests_v2(frequency, classification, year, reporter, OS, month = \"\"):\n",
    "    index = 0\n",
    "    for x in range(len(unpacked_values)):\n",
    "        if reporter == unpacked_values[x][1]:\n",
    "            continue\n",
    "        else:\n",
    "            existence = check_existence(frequency, classification, year, reporter, unpacked_values[x][1], OS, month = month)\n",
    "            if existence:\n",
    "                continue\n",
    "            else:\n",
    "                req = bilateral_requests(frequency, classification, year, reporter, unpacked_values[x][1], OS, month = month)\n",
    "                index += 1\n",
    "                if req.status_code != 200:\n",
    "                    print(f\"The request was not successful for {frequency}, {classification}, {year + month}, {reporter}, {unpacked_values[x][1]}\")\n",
    "                    break\n",
    "                elif index == 4:\n",
    "                    print(f\"Since this is only an example, we stop at the index {index} since you might not want to download all the bilateral data for {reporter} in {year + month}\")\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder does not exist, implying that the file France_All.csv does not exist, continue with this iteration.\n",
      "The folder at /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2016/France/ has been created.\n",
      "/home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2016/France/\n",
      "The country France is in the list with id 251\n",
      "The country All is in the list with id all\n",
      "The url for H4 and trade flows between France and All in 2016 has been created. Processing request...\n",
      "The request for H4, France, All, 2016 has been completed. The HTTP code is: 200\n",
      "http://comtrade.un.org/api/get?max=100000&type=C&freq=A&px=H4&ps=2016&r=251&p=all&rg=1,2&cc=ALL&fmt=csv&head=M\n",
      "Writing .csv file in /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2016/France/\n",
      "File .csv saved in /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2016/France/\n",
      "The folder at /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2016/France/ has been created.\n",
      "/home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2016/France/\n",
      "The country France is in the list with id 251\n",
      "The country Afghanistan is in the list with id 4\n",
      "The url for H4 and trade flows between France and Afghanistan in 2016 has been created. Processing request...\n",
      "The request for H4, France, Afghanistan, 2016 has been completed. The HTTP code is: 200\n",
      "http://comtrade.un.org/api/get?max=100000&type=C&freq=A&px=H4&ps=2016&r=251&p=4&rg=1,2&cc=ALL&fmt=csv&head=M\n",
      "Writing .csv file in /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2016/France/\n",
      "File .csv saved in /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2016/France/\n",
      "The folder at /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2016/France/ has been created.\n",
      "/home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2016/France/\n",
      "The country France is in the list with id 251\n",
      "The country Albania is in the list with id 8\n",
      "The url for H4 and trade flows between France and Albania in 2016 has been created. Processing request...\n",
      "The request for H4, France, Albania, 2016 has been completed. The HTTP code is: 200\n",
      "http://comtrade.un.org/api/get?max=100000&type=C&freq=A&px=H4&ps=2016&r=251&p=8&rg=1,2&cc=ALL&fmt=csv&head=M\n",
      "Writing .csv file in /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2016/France/\n",
      "File .csv saved in /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2016/France/\n",
      "The folder at /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2016/France/ has been created.\n",
      "/home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2016/France/\n",
      "The country France is in the list with id 251\n",
      "The country Algeria is in the list with id 12\n",
      "The url for H4 and trade flows between France and Algeria in 2016 has been created. Processing request...\n",
      "The request for H4, France, Algeria, 2016 has been completed. The HTTP code is: 200\n",
      "http://comtrade.un.org/api/get?max=100000&type=C&freq=A&px=H4&ps=2016&r=251&p=12&rg=1,2&cc=ALL&fmt=csv&head=M\n",
      "Writing .csv file in /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2016/France/\n",
      "File .csv saved in /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/2016/France/\n",
      "Since this is only an example, we stop at the index 4 since you might not want to download all the bilateral data for France in 2016\n"
     ]
    }
   ],
   "source": [
    "reporter_requests_v2(\"A\", \"H4\", \"2016\", \"France\", \"MacOS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see another problem with the API, let us make a request for data that are not in the database (the H4 classification is from 2012, so there are no data using this classification in 1992)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder does not exist, implying that the file France_All.csv does not exist, continue with this iteration.\n",
      "The folder at /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/1992/France/ has been created.\n",
      "/home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/1992/France/\n",
      "The country France is in the list with id 251\n",
      "The country All is in the list with id all\n",
      "The url for H4 and trade flows between France and All in 1992 has been created. Processing request...\n",
      "The request for H4, France, All, 1992 has been completed. The HTTP code is: 200\n",
      "http://comtrade.un.org/api/get?max=100000&type=C&freq=A&px=H4&ps=1992&r=251&p=all&rg=1,2&cc=ALL&fmt=csv&head=M\n",
      "Writing .csv file in /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/1992/France/\n",
      "File .csv saved in /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/1992/France/\n",
      "The folder at /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/1992/France/ has been created.\n",
      "/home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/1992/France/\n",
      "The country France is in the list with id 251\n",
      "The country Afghanistan is in the list with id 4\n",
      "The url for H4 and trade flows between France and Afghanistan in 1992 has been created. Processing request...\n",
      "The request for H4, France, Afghanistan, 1992 has been completed. The HTTP code is: 200\n",
      "http://comtrade.un.org/api/get?max=100000&type=C&freq=A&px=H4&ps=1992&r=251&p=4&rg=1,2&cc=ALL&fmt=csv&head=M\n",
      "Writing .csv file in /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/1992/France/\n",
      "File .csv saved in /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/1992/France/\n",
      "The folder at /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/1992/France/ has been created.\n",
      "/home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/1992/France/\n",
      "The country France is in the list with id 251\n",
      "The country Albania is in the list with id 8\n",
      "The url for H4 and trade flows between France and Albania in 1992 has been created. Processing request...\n",
      "The request for H4, France, Albania, 1992 has been completed. The HTTP code is: 200\n",
      "http://comtrade.un.org/api/get?max=100000&type=C&freq=A&px=H4&ps=1992&r=251&p=8&rg=1,2&cc=ALL&fmt=csv&head=M\n",
      "Writing .csv file in /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/1992/France/\n",
      "File .csv saved in /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/1992/France/\n",
      "The folder at /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/1992/France/ has been created.\n",
      "/home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/1992/France/\n",
      "The country France is in the list with id 251\n",
      "The country Algeria is in the list with id 12\n",
      "The url for H4 and trade flows between France and Algeria in 1992 has been created. Processing request...\n",
      "The request for H4, France, Algeria, 1992 has been completed. The HTTP code is: 200\n",
      "http://comtrade.un.org/api/get?max=100000&type=C&freq=A&px=H4&ps=1992&r=251&p=12&rg=1,2&cc=ALL&fmt=csv&head=M\n",
      "Writing .csv file in /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/1992/France/\n",
      "File .csv saved in /home/moritz/Documents/GitHub/Classes/Session_5/Data/A/H4/1992/France/\n",
      "Since this is only an example, we stop at the index 4 since you might not want to download all the bilateral data for France in 1992\n"
     ]
    }
   ],
   "source": [
    "reporter_requests_v2(\"A\", \"H4\", \"1992\", \"France\", \"MacOS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you try to open one of the .csv file downloaded, you will notice that the request was successful but the first entry of the downloaded file tells you that the data are not available for that query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check what we get from the data availability request if we use this classification and year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The country France is in the list with id 251\n",
      "The url for H4 and trade flows between France and  in 1992 has been created. Processing data availability file...\n",
      "The json for H4, France, , 1992 is now available. Now it is time to unpack it.\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "query_availability_C(\"A\", \"H4\", \"1992\", \"France\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is empty, meaning that the data are not available for this combination of parameter. Let us discuss the problems of the current code and possible solutions. You can improve the code to include those solutions as an exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exceeding number of observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have seen that the query for the data availability does not really help to adrress this problem. We have also noticed that the request is successful but we get a file that in the first entry says \"Result too large: you do not have permissions to access such a large resultset.\".\n",
    "1. Remember that our query asks for imports and exports at the same time. You can rewrite the functions to include trade_flows as argument (adjust also the functions to construct folders, etc. obvisouly). In this way, you reduce the number of observations per file, but increase the number of requests you have to make.\n",
    "2. Include in our main function another function that opens each file that we download to read the first entry. If we get the string \"Results too large etc.\" we can then sae the parameters of this query to a list so that we know which query had the observations problem. Then, we will have to break down those query to find a request with fewer observations. For example, instead of downloading all the commodity codes at once, we split them up (look at the \"cc=\" parameters on the API documentation). Otherwise, split the trade flows as suggested in 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More than 1 request per second"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rate limit should return a 409 error (according to the documentation). This is the same code returned once you exceed 100 requests per hour (again, according to the documentation).\n",
    "1. To avoid the more than 1 request per second problem you just need to include a time.sleep(1) between iterations of the requests. \n",
    "2. Even if you have this problem, it is possible that the UN Comtrade will download a .csv file containing the error as first entry. As for the observations problem, you can just open the file and check the first entry to see if there is a problem. Then, just tell the loop to submit the query again if that was the problem listed in the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage limit, more than 100 requests per hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned above, this should get a 409 status code, so you can deal with it using exception handling and time.sleep(). As for the previous problems, you might get a file that in the first entry report the error, including the time at which you can start submitting requests again. You can extract that and tell Python to restart the requests at that time. Otherwise, just include an index to keep track of how many requests you have made, to stop before the limit, and to tell the code to sleep."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data not available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem you can again use the first entry of the file downloaded, which will tell you that there is a problem of availability with the data. Otherwise, include at the start of the function the query for the avaialbility of the data. If the json from that query is an empty list you know that the data are not available, so you can avoid making that request for the data to the API. The latter approach is better since it should not burn your number of requests per hour (the request for the data availability probably is not included in the usage limit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folder management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are things that you can do to improve folder management of the data downloaded while keeping track of the requests made. You should add a function that deletes the file reporting errors (without data) after you open them to get information about the error contained and the parameter used for that request. In this way you can keep track of the paramaters for which you do not have data due to errors. You should also store these information somewhere since they might be useful at some point.\n",
    "\n",
    "If you want to update your data files over time you can create a function that looks at the creation time of your .csv files and delete them if they are older than your desired threshold. Then, you can download them again. Whether this is useful or not depends on how often UN Comtrade revises old data. For example, they might never change the content of files for trade flows between countries in 1973. In that case, deleting the old file and downloading it again is useless since there are no changes to the data. Instead, they might update trade flows data for the last 2-3 years, so you might want to update the files associated to this time window."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
